{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "import json\n",
    "import urllib\n",
    "import argparse\n",
    "import webbrowser\n",
    "import re\n",
    "import argparse\n",
    "import webbrowser\n",
    "import sys\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from pymediainfo import MediaInfo\n",
    "from libs.html import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sets up the logger that is used throughout the program as a means of tracking issues, successes, and metrics for each function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger('PyMovie')\n",
    "hdlr = logging.FileHandler('PyMovie_log.txt')\n",
    "formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
    "hdlr.setFormatter(formatter)\n",
    "logger.addHandler(hdlr) \n",
    "logger.setLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is used to clean up file names that may have dates, extraneous words in parentheses, etc. By normalizing the names, we hope to have greater success when querying the IMDB API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanTitle(filename):\n",
    "    title = re.sub(r'\\.(\\w|\\d){2,4}$',\"\",filename) #Remove file extension\n",
    "    title = re.sub(r'(\\(|\\[)(.*)(\\)|\\])',\"\",title) #Remove anything in parentheses or brackets\n",
    "    title = re.sub(r'\\:',\"\",title) #Remove Colons\n",
    "    title = re.sub(r'(\\s)?\\-(\\s)?',\" \",title) #Remove hyphens for subtitles\n",
    "    title = re.sub(r'(\\s)[0-9]{1,2}(\\s)', ' ',title) #Remove Numeric identifiers\n",
    "    title = title.strip() #Trim Whitespace\n",
    "    return title    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes a directory name and ensure it ends with a slash (i.e., \"/\"). This keeps the later functions from throwing errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dirClean(directory_name):\n",
    "    if directory_name[-1] != \"/\":\n",
    "        directory_name = directory_name + \"/\"\n",
    "    return(directory_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function reads the names of files in a provided directory and then runs those files through the IMDB API to collect movie information.  The final output are two .csv files; one for movies that were found through the API and another for files that weren't found.  This function also checks against previous runs of the function to limit the number of API calls.  Finally, this function downloads and stores movie poster artwork for later use in web page construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crawl(source_dir):\n",
    "    begin = datetime.datetime.now() #For recording runtime\n",
    "    logger.info('crawl() START')\n",
    "    \n",
    "    source_dir = dirClean(source_dir)\n",
    "    movie_list = os.listdir(source_dir)\n",
    "    columns = ['ID','title','year','director','actors','plot','genre_primary','genre_other','poster','rating_imdb','rating_metacritic','rating_rotten','filename','filesize','duration','resolution','aspect']\n",
    "    \n",
    "    startposters = len(os.listdir(\"./pages/images/\")) - 4\n",
    "    \n",
    "    #Attempt to load existing data. If it is not there, create empty dataframe instead\n",
    "    if os.path.exists(\"movieDF.csv\"):\n",
    "        movieDF = pd.read_csv(\"movieDF.csv\")\n",
    "        startrows = len(movieDF)\n",
    "        if os.path.exists(\"failedmovieDF.csv\"):\n",
    "            moviefailDF = pd.read_csv(\"failedmovieDF.csv\")\n",
    "        else:\n",
    "            moviefailDF = pd.DataFrame(columns = ['title'])\n",
    "        #Remove rows from movieDF for movies that no longer appear in the directory\n",
    "        for movie in movieDF['filename']:    \n",
    "            if movie not in movie_list:\n",
    "                movieDF = movieDF[movieDF.filename != movie]\n",
    "                logger.info(\"Removed \" + movie + \" from movie library.\")\n",
    "                #Remove photos for movies that no longer appear in the directory\n",
    "                title = cleanTitle(movie)\n",
    "                if title + '.jpg' in os.listdir(\"./pages/images/\"):\n",
    "                    os.remove('./pages/images/' + title + '.jpg')\n",
    "                    logger.info('Removed ' + title + '.jpg from poster folder.')\n",
    "    else: \n",
    "        movieDF = pd.DataFrame(columns=columns)\n",
    "        moviefailDF = pd.DataFrame(columns = ['title'])\n",
    "        startrows = len(movieDF)\n",
    "    \n",
    "    for movie in movie_list:\n",
    "                # The following 2 lines may need to be hacked at dependent of naming\n",
    "                # Scheme. Or, a more dynamic solution may be needed to suffice.\n",
    "                movieInfo = pd.DataFrame(columns=columns)\n",
    "                title = cleanTitle(movie[0:])\n",
    "                \n",
    "                #If movie is already in the dataframe than skip to the next iteration of the loop\n",
    "                if title in movieDF['title'].values:\n",
    "                    #If movie poster isn't downloaded, then download it based on stored URL\n",
    "                    if title + '.jpg' not in os.listdir(\"./pages/images/\"):\n",
    "                            os.system('wget -O \"pages/images/' + title + '.jpg\" ' + movieDF.loc[movieDF['title'] == title, 'poster'].values[0])\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    # Using API from http://www.omdbapi.com/\n",
    "                    url = \"http://www.omdbapi.com/?t=\" + urllib.parse.quote(title) + '&tomatoes=true'\n",
    "                    # Now dowloading and parsing the results as json file so we can work on it locally\n",
    "                    reader = codecs.getreader(\"utf-8\")\n",
    "                    data = json.load(reader(urllib.request.urlopen(url)))\n",
    "\n",
    "                    try:\n",
    "                        movie_imdbID = data[\"imdbID\"]\n",
    "                        movie_title = data[\"Title\"]\n",
    "                        movie_year = data[\"Year\"]\n",
    "                        movie_director = data[\"Director\"]\n",
    "                        movie_actors = data[\"Actors\"]\n",
    "                        movie_plot = data[\"Plot\"]\n",
    "                        movie_genre_1 = data[\"Genre\"].split(\",\")[0]\n",
    "                        movie_genre_2 = data[\"Genre\"].split(\",\")[1:]\n",
    "                        movie_poster = data[\"Poster\"]\n",
    "                        \n",
    "                        #If poster file doesn't exist in image directory then download it based on API URL\n",
    "                        if title + '.jpg' not in os.listdir(\"./pages/images/\"):\n",
    "                            filename = title\n",
    "                            os.system('wget -O \"pages/images/' + filename + '.jpg\" ' + movie_poster)\n",
    "                        \n",
    "                        movie_rating_imdb = data[\"imdbRating\"]\n",
    "                        movie_rating_metacritic = data[\"Metascore\"]\n",
    "                        movie_rating_rotten = data[\"tomatoMeter\"]\n",
    "                        movie_filename = movie\n",
    "                        \n",
    "                        media_info = MediaInfo.parse(source_dir + movie)\n",
    "\n",
    "                        movie_filesize = media_info.tracks[0].other_file_size[0]\n",
    "                        movie_duration = media_info.tracks[0].other_duration[2]\n",
    "                        movie_resolution = str(media_info.tracks[1].sampled_width + \" * \" + media_info.tracks[1].sampled_height)\n",
    "                        movie_aspect = media_info.tracks[1].other_display_aspect_ratio[0]\n",
    "\n",
    "                        movieInfo.loc[1] = [movie_imdbID, movie_title, movie_year, movie_director, movie_actors, movie_plot, movie_genre_1,movie_genre_2,\n",
    "                                                  movie_poster, movie_rating_imdb, movie_rating_metacritic, movie_rating_rotten,\n",
    "                                            movie_filename, movie_filesize, movie_duration, movie_resolution, movie_aspect]\n",
    "\n",
    "                   \n",
    "                        movieDF = movieDF.append(movieInfo)\n",
    "                        logger.info(\"Success - \" + movie)\n",
    "                        logger.info(\"Success URL: \" + url)   \n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        failMovie = pd.DataFrame(columns=['title'])\n",
    "                        failMovie.loc[1] = title\n",
    "                        moviefailDF = moviefailDF.append(failMovie)\n",
    "                        print(e)\n",
    "                        logger.info(\"Failed - \" + movie)\n",
    "                        logger.info(\"Fail URL: \" + url) \n",
    "                        pass\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "    movieDF = movieDF.sort_values(by='title')\n",
    "    movieDF.to_csv('movieDF.csv',index=False)\n",
    "    moviefailDF.to_csv('failedmovieDF.csv',index=False)\n",
    "    \n",
    "    #write to Logger\n",
    "    run_columns = ['date','time','runtime','movie_delta','movie_total','poster_delta','poster_total']\n",
    "    \n",
    "    if os.path.exists(\"runData.csv\"):\n",
    "        run_data = pd.read_csv(\"runData.csv\")\n",
    "    else: \n",
    "        run_data = pd.DataFrame(columns=run_columns)\n",
    "        \n",
    "    end = datetime.datetime.now()\n",
    "    endrows = len(movieDF)\n",
    "    endposters = len(os.listdir(\"./pages/images/\")) - 4\n",
    "    now = datetime.datetime.now()\n",
    "    \n",
    "    runInfo = pd.DataFrame(columns=run_columns)\n",
    "    runInfo.loc[1] = [now.strftime('%Y-%m-%d'),now.strftime('%H:%M:%S'),end-begin, 0-(startrows-endrows),endrows,\n",
    "                     0-(startposters-endposters), endposters]\n",
    "    run_data = run_data.append(runInfo)\n",
    "    run_data.to_csv('runData.csv',index=False)\n",
    "    \n",
    "    logger.info('Crawl() function complete')\n",
    "    print(\"crawl() END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function creates a website that has a main page that displays movie posters and names and then subpages for each movie that was successfully found through the IMDB API. Added a jquery table that allows the user to sort and search for movies based on title, genre and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def htmlout(movie_file, source_dir):\n",
    "    movieDF = pd.read_csv(movie_file)\n",
    "    output_file = \"movies.html\"\n",
    "    try:\n",
    "        # Opening and generating final html (for example movies.html) file\n",
    "        html_file = open(output_file, \"w\")\n",
    "        html_file.write(header)\n",
    "        html_file.write('<div class=\"medium-12 columns\">')\n",
    "        html_file.write('<h1 style=\"color:white\" class=\"titleshadow\">PyMovie Share</h1>')\n",
    "        html_file.write('<hr class=\"style-four\"></div>')\n",
    "        html_file.write('<div class=\"row\">')\n",
    "        \n",
    "        #Write Table Data\n",
    "        html_file.write('<table id=\"movieTable\" class=\"display\" cellspacing=\"0\" width=\"100%\">')\n",
    "        html_file.write('<thead style=\"font-size:125%\"><tr><th rowspan=\"2\"></th><th rowspan=\"2\">Title</th><th rowspan=\"2\">Genre</th><th colspan=\"3\"><center>Ratings</center></th><th rowspan=\"2\">Actors</th></tr>')\n",
    "        html_file.write('<tr><th>IMDB</th><th>Metacritic</th><th>Rotten Tomatoes</th></tr></thead><tbody>')\n",
    "\n",
    "        for index, row in movieDF.iterrows():\n",
    "            html_file.write('<tr>')\n",
    "            html_file.write('<td><div class=\"face pic\"><a href=\"file://' + os.getcwd() +'/pages/' + row['title'] + '.html\"><img src=\"pages/images/' + row['title'] + '.jpg\" style=\"height:100%;width:200px;box-shadow: 4px 4px 2px #9a9a9a\"></a></div></td>')\n",
    "            html_file.write('<td><a href=\"file://' + os.getcwd() +'/pages/' + row['title'] + '.html\" style=\"font-size:175%\">' + row['title'] +'</a></td>')\n",
    "            html_file.write('<td style=\"font-size:125%; text-align:center\">' + row['genre_primary'] +'</td>')\n",
    "            html_file.write('<td style=\"font-size:135%; text-align:center\">' + str(row['rating_imdb']) +'</td>')\n",
    "            html_file.write('<td><center>')\n",
    "            \n",
    "            if row['rating_metacritic'] <= 20: \n",
    "                html_file.write('<span class=\"metalow\">' + str(int(row['rating_metacritic']))+'</span></center></td>')\n",
    "            elif 20 < row['rating_metacritic'] <= 40: \n",
    "                html_file.write('<span class=\"metamedlow\">' + str(int(row['rating_metacritic']))+'</span></center></td>')   \n",
    "            elif 40 < row['rating_metacritic'] <= 60: \n",
    "                html_file.write('<span class=\"metamedium\">' + str(int(row['rating_metacritic']))+'</span></center></td>')    \n",
    "            elif 60 < row['rating_metacritic'] <= 80: \n",
    "                html_file.write('<span class=\"metamedhigh\">' + str(int(row['rating_metacritic']))+'</span></center></td>')    \n",
    "            elif row['rating_metacritic'] > 80: \n",
    "                html_file.write('<span class=\"metahigh\">' + str(int(row['rating_metacritic']))+'</span></center></td>') \n",
    "            else:\n",
    "                html_file.write('<span class=\"metaNA\">NA</span></center></td>')\n",
    "            \n",
    "            html_file.write('<td style=\"font-size:135%; text-align:center\">' + str(row['rating_rotten']) + ' ')\n",
    "            \n",
    "            if row['rating_rotten'] < 60: \n",
    "                html_file.write('<img src=\"pages/images/rottenicon.png\" style=\"width:30px; display:inline\"></div></td>') \n",
    "            elif row['rating_rotten'] >= 60: \n",
    "                html_file.write('<img src=\"pages/images/freshicon.png\" style=\"width:30px; display:inline\"></div></td>')\n",
    "            else:\n",
    "                html_file.write('</td></tr>')\n",
    "        \n",
    "            html_file.write('<td>' + row['actors'] +'</td></tr>')\n",
    "        \n",
    "        #Close Table\n",
    "        html_file.write('</tbody></table>')\n",
    "        \n",
    "        # Generate some stats at on the bottom of the html page\n",
    "        html_file.write('<div class=\"row\">')\n",
    "        html_file.write('<hr>')\n",
    "        \n",
    "\n",
    "        html_file.write(footer)\n",
    "        html_file.close()\n",
    "        \n",
    "        for index, row in movieDF.iterrows():\n",
    "            movie_page = \"./pages/\" + row['title'] + \".html\"     \n",
    "            html_file = open(movie_page, \"w\")\n",
    "            html_file.write(header_sub)\n",
    "            \n",
    "            html_file.write('<div class=\"fixed\"><a href=\"../movies.html\"><img src=\"images/backarrow.png\" style=\"width:80px\"></a></div><div class=\"row\">')\n",
    "            html_file.write('<h1 style=\"color:white; display:inline\" class=\"titleshadow\">' + row['title'] + ' (' + str(row['year']) +')</h1>')\n",
    "            html_file.write('<hr class=\"style-four\"></div>')\n",
    "            \n",
    "            html_file.write('<div class=\"row\">')\n",
    "            html_file.write('<div class=\"medium-5 columns\">')\n",
    "            html_file.write('<div class=\"panel\">')\n",
    "            html_file.write('<img src=\"images/' + row['title'] + '.jpg\" style=\"height:100%;width:375px;box-shadow: 5px 5px 2px #474747\"/>')\n",
    "            html_file.write('</div></div>')\n",
    "            html_file.write('<div class=\"medium-7 columns\">')\n",
    "            html_file.write('<div class=\"panel\">')\n",
    "            html_file.write('<div class=\"medium-4 columns\" style=\"border-right:1px solid #c7c9cc;height:90px\">')\n",
    "            html_file.write('<center><p style=\"font-size:125%; padding-bottom: 20px\"><b>IMDB</b><br> ' + str(row['rating_imdb']) + '/10</p></center>')\n",
    "            html_file.write('<vr>')\n",
    "            html_file.write('</div><div class=\"medium-4 columns\" style=\"border-right:1px solid #c7c9cc;height:100px\">')\n",
    "            html_file.write('<center><div style=\"font-size:125%; padding-bottom: 10px\"><b>Metacritic</b></div>')\n",
    "                            \n",
    "            if row['rating_metacritic'] <= 20: \n",
    "                html_file.write('<span class=\"metalow\">' + str(int(row['rating_metacritic']))+'</span></center>')\n",
    "            elif 20 < row['rating_metacritic'] <= 40: \n",
    "                html_file.write('<span class=\"metamedlow\">' + str(int(row['rating_metacritic']))+'</span></center>')   \n",
    "            elif 40 < row['rating_metacritic'] <= 60: \n",
    "                html_file.write('<span class=\"metamedium\">' + str(int(row['rating_metacritic']))+'</span></center>')    \n",
    "            elif 60 < row['rating_metacritic'] <= 80: \n",
    "                html_file.write('<span class=\"metamedhigh\">' + str(int(row['rating_metacritic']))+'</span></center>')    \n",
    "            elif row['rating_metacritic'] > 80: \n",
    "                html_file.write('<span class=\"metahigh\">' + str(int(row['rating_metacritic']))+'</span></center>') \n",
    "            else:\n",
    "                html_file.write('<span class=\"metaNA\">NA</p></center>')\n",
    "            \n",
    "            html_file.write('</div>')\n",
    "            html_file.write('<center><p style=\"font-size:125%; padding-bottom: 20px\"><b>Rotten Tomatoes</b><br> ' + str(row['rating_rotten']) + ' ')\n",
    "            \n",
    "            if row['rating_rotten'] < 60: \n",
    "                html_file.write('<img src=\"images/rottenicon.png\" style=\"width:30px; display:inline\"></p></center>') \n",
    "            elif row['rating_rotten'] >= 60: \n",
    "                html_file.write('<img src=\"images/freshicon.png\" style=\"width:30px; display:inline\"></p></center>')\n",
    "            else:\n",
    "                html_file.write('</td></tr>')\n",
    "\n",
    "            html_file.write('<hr>')\n",
    "            \n",
    "            html_file.write('<p><b>Plot:</b> ' + str(row['plot']) + '</p>')\n",
    "            html_file.write('<p><b>Actors:</b> ' + str(row['actors']) + '</p>')\n",
    "            html_file.write('<p><b>Director:</b> ' + str(row['director']) + '</p>')\n",
    "            \n",
    "            html_file.write('<hr>')\n",
    "            html_file.write('<div class=\"medium-4 columns\">')\n",
    "            html_file.write(\"<p><b>Runtime:</b> \" + str(row['duration']) + \"</p>\")\n",
    "            html_file.write('</div><div class=\"medium-4 columns\">')\n",
    "            html_file.write(\"<p><b>Filesize:</b> \" + str(row['filesize']) + \"</p>\")\n",
    "            html_file.write('</div>')\n",
    "            html_file.write(\"<p><b>Resolution:</b> \" + str(row['resolution']) + \"</p>\")\n",
    "            html_file.write('<hr>')\n",
    "            html_file.write(\n",
    "                '<a href=\"file://' + source_dir + row['filename'] + '\" download class=\"button large radius success expand\">Download</a>') \n",
    "            html_file.write(\"</div></div></div>\")\n",
    "\n",
    "            html_file.write(footer_sub)\n",
    "            html_file.close()\n",
    "            \n",
    "        # Opening the browser and presenting the summary html page\n",
    "        webbrowser.open('file://' + os.path.realpath(output_file))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"***** Error. Maybe try to run the script again but bit later? *****\")\n",
    "        logging.critical('Critical error -- Abort Script')\n",
    "        sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
