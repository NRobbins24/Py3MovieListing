{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import codecs\n",
    "import json\n",
    "import urllib\n",
    "import argparse\n",
    "import webbrowser\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "import sys\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from libs.html import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Logging\n",
    "\n",
    "Sets up the logger that is used throughout the program as a means of tracking issues, successes, and metrics for each function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger('PyMovie')\n",
    "hdlr = logging.FileHandler('Data/PyMovie_log.txt')\n",
    "formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
    "hdlr.setFormatter(formatter)\n",
    "logger.addHandler(hdlr) \n",
    "logger.setLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Movie Titles\n",
    "These three functions used to clean up file names that may have dates, extraneous words in parentheses, etc. By normalizing the names, we hope to have greater success when querying the IMDB API.  These different styles of normalizing are fed into the API through the getOMDB() function.\n",
    "\n",
    "*cleanTitle3()* is used as a helper function for naming of poster files and for text output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanTitle(filename):\n",
    "    title = re.sub(r'\\.(\\w|\\d){2,4}$',\"\",filename) #Remove file extension\n",
    "    title = re.sub(r'(\\(|\\[)(.*)(\\)|\\])',\"\",title) #Remove anything in parentheses or brackets\n",
    "    title = re.sub(r'\\:',\"\",title) #Remove Colons\n",
    "    title = re.sub(r'(\\s)?\\-(\\s)?',\" \",title) #Remove hyphens for subtitles\n",
    "    title = re.sub(r'(\\s)[0-9]{1,2}(\\s)', ' ',title) #Remove Numeric identifiers\n",
    "    title = title.strip() #Trim Whitespace\n",
    "    return title  \n",
    "\n",
    "def cleanTitle2(filename):\n",
    "    title = re.sub(r'\\.(\\w|\\d){2,4}$',\"\",filename) #Remove file extension\n",
    "    title = re.sub(r'(\\(|\\[)(.*)(\\)|\\])',\"\",title) #Remove anything in parentheses or brackets\n",
    "    title = re.sub(r'\\:',\"\",title) #Remove Colons\n",
    "    title = re.sub(r'[\\w\\s]*(\\s)?\\-(\\s)?',\"\",title) #Submit only subtitles\n",
    "    title = title.strip() #Trim Whitespace\n",
    "    return title\n",
    "\n",
    "\n",
    "def cleanTitle3(filename):\n",
    "    title = re.sub(r'\\.(\\w|\\d){2,4}$',\"\",filename) #Remove file extension\n",
    "    return title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build URL for API\n",
    "This function determines whether the filename contains a release year and, if so, includes the year as a parameter when searching the API. If it does not, only the title is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanURL(filename, title):\n",
    "    year = re.search(r'(\\[|\\()([0-9]{4})(\\]|\\))',filename)\n",
    "    if year:\n",
    "        year= re.sub(r\"(\\[|\\(|\\]|\\))\",\"\", year.group(0))\n",
    "    else:\n",
    "        year=\"\"\n",
    "    if not year == \"\":\n",
    "        url = \"http://www.omdbapi.com/?t=\" + urllib.parse.quote(title) + '&y=' + urllib.parse.quote(year) + '&tomatoes=true&type=movie'\n",
    "    else:\n",
    "        url = \"http://www.omdbapi.com/?t=\" + urllib.parse.quote(title) + '&tomatoes=true&type=movie'\n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving From OMDB\n",
    "This function uses two of the cleantitleX() functions to normalize the movie title, feed it into the API, and, if successful, download the resulting JSON.  The API always passes back a parameter named \"Response\" that is True if the query returned a result and False if it did not. The function is set up to only try further responses if the intial response doesn't work. There is room for improvement in this code and I will work to clean it up as time permits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getOMDB(movieTitle):\n",
    "    \n",
    "    #First Attempt\n",
    "    title = cleanTitle(movieTitle)\n",
    "    url = cleanURL(movieTitle, title)\n",
    "    reader = codecs.getreader(\"utf-8\")\n",
    "    data = json.load(reader(urllib.request.urlopen(url)))\n",
    "\n",
    "    if data[\"Response\"] == \"True\":\n",
    "        return data\n",
    "    else:\n",
    "        #Second Attempt\n",
    "        title = cleanTitle2(movieTitle)\n",
    "        url = cleanURL(movieTitle, title)\n",
    "        reader = codecs.getreader(\"utf-8\")\n",
    "        data = json.load(reader(urllib.request.urlopen(url)))\n",
    "\n",
    "        if data[\"Response\"] == \"True\":\n",
    "            return data\n",
    "        else:\n",
    "            print(\"exit\")\n",
    "            return()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function: Add '/' to end of directory\n",
    "\n",
    "This function takes a directory name and ensure it ends with a slash (i.e., \"/\"). This keeps the later functions from throwing errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dirClean(directory_name):\n",
    "    if directory_name[-1] != \"/\":\n",
    "        directory_name = directory_name + \"/\"\n",
    "    return(directory_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function: Validate User Input\n",
    "In the *crawl()* function, users are asked to enter a number. This function validates whether an acceptable input was entered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validateInput(response):\n",
    "    if response == \"\":\n",
    "        print(\"Please Enter A Value\")\n",
    "        return(False)\n",
    "    if response.isdigit():\n",
    "        response = int(response)\n",
    "        if response > 0 and response < 4:\n",
    "            return(True)          \n",
    "        else:\n",
    "            print(\"Please Enter One of the Values Shown\")\n",
    "            return(False)\n",
    "    else:\n",
    "        print(\"Please Enter a Number\")\n",
    "        return(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection Function\n",
    "\n",
    "This function reads the names of files in a provided directory and then runs those files through the IMDB API to collect movie information.  The final output are two .csv files; one for movies that were found through the API and another for files that weren't found.  This function also checks against previous runs of the function to limit the number of API calls.  Finally, this function downloads and stores movie poster artwork for later use in web page construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crawl(source_dir):\n",
    "    begin = datetime.datetime.now() #For recording runtime\n",
    "    logger.info('crawl() START')\n",
    "    \n",
    "    source_dir = dirClean(source_dir)\n",
    "    movie_list = os.listdir(source_dir)\n",
    "    columns = ['ID','title','year','duration','release_date','mpaa_rating','director','actors','plot','genre','poster','rating_imdb','rating_metacritic','rating_rotten','awards','boxoffice','filename','filesize']\n",
    "    \n",
    "    startposters = len(os.listdir(\"./Site/pages/posters/\"))\n",
    "    \n",
    "    #Attempt to load existing data. If it is not there, create empty dataframe instead\n",
    "    if os.path.exists(\"Data/movieDF.csv\"):\n",
    "        movieDF = pd.read_csv(\"Data/movieDF.csv\")\n",
    "        startrows = len(movieDF)\n",
    "        if os.path.exists(\"Data/failedmovieDF.csv\"):\n",
    "            moviefailDF = pd.read_csv(\"Data/failedmovieDF.csv\")\n",
    "        else:\n",
    "            moviefailDF = pd.DataFrame(columns = ['title'])\n",
    "        #Remove rows from movieDF for movies that no longer appear in the directory\n",
    "        for movie in movieDF['filename']:    \n",
    "            if movie not in movie_list:\n",
    "                movieDF = movieDF[movieDF.filename != movie]\n",
    "                logger.info(\"Removed \" + movie + \" from movie library.\")\n",
    "                #Remove photos for movies that no longer appear in the directory\n",
    "                title = cleanTitle(movie)\n",
    "                if title + '.jpg' in os.listdir(\"./Site/pages/posters/\"):\n",
    "                    os.remove('./Site/pages/posters/' + title + '.jpg')\n",
    "                    logger.info('Removed ' + title + '.jpg from poster folder.')\n",
    "                if title + '.html' in os.listdir(\"./Site/pages/\"):\n",
    "                    os.remove('./Site/pages/' + title + '.html')\n",
    "                    logger.info('Removed ' + title + '.html from webpages folder.')\n",
    "    else: \n",
    "        movieDF = pd.DataFrame(columns=columns)\n",
    "        moviefailDF = pd.DataFrame(columns = ['title'])\n",
    "        startrows = len(movieDF)\n",
    "    \n",
    "    ############ Experimenting with Optional Manual Search ################\n",
    "    print(\"Posters, descriptions, and other metadata will now be downloaded for your movies. This script will attempt to match the filenames you gave your movies to the omdbapi.com API.  This is not an exact process and may result in errors or failures to match. Below you are given two options for completing this search.\")\n",
    "    print(\"\")\n",
    "    print(\"*  The 'Manual' search will ask you to confirm whether the omdb API match is correct and, if not, will ask prompt you to enter a new title.\")\n",
    "    print(\"*  The 'Automatic' search will use whatever movie is returned by the omdb API.\")\n",
    "    print(\"\")\n",
    "    print(\"Enter the number of the search mode you would like to use and press enter.\")\n",
    "    print(\"1. Manual Search\")\n",
    "    print(\"2. Automatic Search\")\n",
    "    print(\"3. Exit\")\n",
    "\n",
    "    valid = False\n",
    "    while valid == False:\n",
    "        movieResponse = input('')\n",
    "        valid = validateInput(movieResponse)\n",
    "    print(\"--------------------------------------------------\")               \n",
    "            \n",
    "    #######################################################################\n",
    "    \n",
    "    \n",
    "    for movie in movie_list:\n",
    "                # The following 2 lines may need to be hacked at dependent of naming\n",
    "                # Scheme. Or, a more dynamic solution may be needed to suffice.\n",
    "                movieInfo = pd.DataFrame(columns=columns)\n",
    "                title = cleanTitle(movie[0:])\n",
    "                \n",
    "                #If movie is already in the dataframe than skip to the next iteration of the loop\n",
    "                if movie in movieDF['filename'].values:\n",
    "                    #If movie poster isn't downloaded, then download it based on stored URL\n",
    "                    if cleanTitle3(movie) + '.jpg' not in os.listdir(\"./Site/pages/posters/\"):\n",
    "                        print(movie)\n",
    "                        print(pd.isnull(movieDF.loc[movieDF['filename'] == movie, 'poster'].values[0]))\n",
    "                        if not pd.isnull(movieDF.loc[movieDF['filename'] == movie, 'poster'].values[0]):\n",
    "                            os.system('wget -O \"Site/pages/posters/' + cleanTitle3(movie) + '.jpg\" ' + movieDF.loc[movieDF['filename'] == movie, 'poster'].values[0])\n",
    "                    continue\n",
    "                \n",
    "                try:                   \n",
    "                    if movie.startswith(\".\"):\n",
    "                        continue\n",
    "                        \n",
    "                    ############ Experimenting with Optional Manual Search ################\n",
    "                    if movieResponse == \"1\":\n",
    "                        movieLoop = \"2\"\n",
    "                        searchmovie = movie\n",
    "                        while movieLoop == \"2\":\n",
    "                            data = getOMDB(searchmovie)\n",
    "                            try:\n",
    "                                print(\"\")\n",
    "                                print(\"Looking Up:  \" + searchmovie)\n",
    "                                print(\"--> \" + data[\"Title\"] + \" (\" + data[\"Year\"].split(\" \")[0] +\")\")\n",
    "                                print(\"-->\" + data[\"Plot\"])\n",
    "                                print(\"\")\n",
    "                                print(\"Is this the movie you wanted?\")\n",
    "                                print(\"1. Yes\")\n",
    "                                print(\"2. No\")\n",
    "                                print(\"3. Exit Metadata Search\")\n",
    "                                valid = False\n",
    "                                while valid == False:\n",
    "                                    movieLoop = input('Is this the movie you wanted?:')\n",
    "                                    valid = validateInput(movieLoop)\n",
    "                            except:\n",
    "                                print(\"\")\n",
    "                                print(\"--> Movie Not Found\")\n",
    "                                movieLoop = \"2\"\n",
    "\n",
    "                            if movieLoop == \"3\":\n",
    "                                data=[]\n",
    "                                movieResponse = \"3\"\n",
    "                                break\n",
    "                            \n",
    "                            if movieLoop== \"2\":\n",
    "                                print(\"\")\n",
    "                                searchmovie = input('Try a different title (or type \"next\" to move on):')\n",
    "\n",
    "                            if movieLoop == \"1\" or searchmovie == \"next\":\n",
    "                                print(\"--------------------------------------------------\")\n",
    "                                break\n",
    "                    if movieResponse == \"2\":\n",
    "                            data = getOMDB(movie)\n",
    "                            print(\"Searching for:  \" + cleanTitle3(movie))\n",
    "                    if movieResponse == \"3\":\n",
    "                        continue\n",
    "                    #######################################################################\n",
    "\n",
    "\n",
    "                    try:\n",
    "                        movie_imdbID = data[\"imdbID\"]\n",
    "                        movie_title = unidecode(data[\"Title\"])\n",
    "                        movie_year = data[\"Year\"].split(\" \")[0]\n",
    "                        movie_duration = data[\"Runtime\"]\n",
    "                        movie_release = data[\"Released\"]\n",
    "                        movie_director = unidecode(data[\"Director\"])\n",
    "                        movie_actors = unidecode(data[\"Actors\"])\n",
    "                        movie_plot = unidecode(data[\"Plot\"])\n",
    "                        movie_genre = data[\"Genre\"]\n",
    "                        movie_poster = data[\"Poster\"]\n",
    "                        movie_rating = data[\"Rated\"]\n",
    "                        movie_awards = data[\"Awards\"]\n",
    "                        movie_money = data[\"BoxOffice\"]\n",
    "                        \n",
    "                        #If poster file doesn't exist in image directory then download it based on API URL\n",
    "                        if cleanTitle3(movie) + '.jpg' not in os.listdir(\"./Site/pages/posters/\"):\n",
    "                            filename = cleanTitle3(movie)\n",
    "                            os.system('wget -O \"Site/pages/posters/' + filename + '.jpg\" ' + movie_poster)\n",
    "                        \n",
    "                        movie_rating_imdb = data[\"imdbRating\"]\n",
    "                        movie_rating_metacritic = data[\"Metascore\"]\n",
    "                        movie_rating_rotten = data[\"tomatoMeter\"]\n",
    "                        movie_filename = movie\n",
    "                        \n",
    "                        movie_filesize = os.path.getsize(source_dir + movie)                   \n",
    "                        \n",
    "\n",
    "                        movieInfo.loc[1] = [movie_imdbID, movie_title, movie_year, movie_duration, movie_release, movie_rating, movie_director, movie_actors, \n",
    "                                            movie_plot, movie_genre,movie_poster, movie_rating_imdb, movie_rating_metacritic, \n",
    "                                            movie_rating_rotten, movie_awards, movie_money, movie_filename, movie_filesize]\n",
    "                        \n",
    "                        movieDF = movieDF.append(movieInfo)\n",
    "                        \n",
    "                        logger.info(\"Success - \" + movie)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        failMovie = pd.DataFrame(columns=['title'])\n",
    "                        failMovie.loc[1] = title\n",
    "                        moviefailDF = moviefailDF.append(failMovie)\n",
    "                        print(e)\n",
    "                        logger.info(\"Failed - \" + movie)\n",
    "                        pass\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "    movieDF = movieDF.sort_values(by='title')\n",
    "    movieDF.to_csv('Data/movieDF.csv',index=False)\n",
    "    moviefailDF.to_csv('Data/failedmovieDF.csv',index=False)\n",
    "    \n",
    "    #write to Logger\n",
    "    run_columns = ['date','time','runtime','movie_delta','movie_total','poster_delta','poster_total']\n",
    "    \n",
    "    if os.path.exists(\"Data/runData.csv\"):\n",
    "        run_data = pd.read_csv(\"Data/runData.csv\")\n",
    "    else: \n",
    "        run_data = pd.DataFrame(columns=run_columns)\n",
    "        \n",
    "    end = datetime.datetime.now()\n",
    "    endrows = len(movieDF)\n",
    "    endposters = len(os.listdir(\"./Site/pages/posters/\"))\n",
    "    now = datetime.datetime.now()\n",
    "    \n",
    "    runInfo = pd.DataFrame(columns=run_columns)\n",
    "    runInfo.loc[1] = [now.strftime('%Y-%m-%d'),now.strftime('%H:%M:%S'),end-begin, 0-(startrows-endrows),endrows,\n",
    "                     0-(startposters-endposters), endposters]\n",
    "    run_data = run_data.append(runInfo)\n",
    "    run_data.to_csv('Data/runData.csv',index=False)\n",
    "    \n",
    "    logger.info('Crawl() function complete')\n",
    "    print(\"crawl() END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UI Building Function\n",
    "\n",
    "This function creates a website that has a main page that displays movie posters and names and then subpages for each movie that was successfully found through the IMDB API. Added a jquery table that allows the user to sort and search for movies based on title, genre and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def htmlout(movie_file, source_dir):\n",
    "    logger.info('htmlout() START')\n",
    "    \n",
    "    movieDF = pd.read_csv(\"Data/\" + movie_file)\n",
    "    output_file = \"Site/movies.html\"\n",
    "    \n",
    "    movieDF['genre_all'] = None\n",
    "    for row in range(0,movieDF.shape[0]):\n",
    "        movieDF.ix[row, 'genre_all'] = str(movieDF.ix[row, 'genre'].lower().split())\n",
    "        movieDF.ix[row, 'genre_all'] = re.sub(\",'\",'\"',movieDF.ix[row, 'genre_all'])\n",
    "        movieDF.ix[row, 'genre_all'] = re.sub(\"'\",'\"',movieDF.ix[row, 'genre_all'])\n",
    "    \n",
    "    try:\n",
    "        # Opening and generating final html (for example movies.html) file\n",
    "        html_file = open(output_file, \"w\")\n",
    "        html_file.write(header)\n",
    "        \n",
    "        #Add Button Group\n",
    "        allgenre = []\n",
    "        for movie in movieDF['genre']:\n",
    "            allgenre += movie.split(\",\")\n",
    "        allgenre = np.sort(list(set(allgenre)))\n",
    "        \n",
    "        for genre in allgenre:\n",
    "            html_file.write('<button class=\"filterButton\" data-group=\"' + genre.lower().strip() + '\">' + genre.strip() + '</button>')\n",
    "        html_file.write('</div></div></div>')\n",
    "        \n",
    "        #Add Content Sections\n",
    "        html_file.write('<div class =\"col-md-11\" style=\"padding-bottom:30px\">')\n",
    "        html_file.write('<section id=\"demo\"><center>')\n",
    "        html_file.write('<div class=\"container\">')\n",
    "        html_file.write('<div id=\"grid\" class=\"row my-shuffle-container\">')\n",
    "\n",
    "        for index, row in movieDF.iterrows():\n",
    "            title = cleanTitle(row['filename'])\n",
    "            \n",
    "            html_file.write(\"<figure name='cover' class='col-2@md col-2@sm col-2@xs picture-item' data-groups='\" + row['genre_all'] + \"' data-date-created='\" + str(row['year']) + \"-06-01' data-title='\" + row['title'] + \"'>\")\n",
    "            html_file.write('<div class=\"picture-item__inner\">')\n",
    "            html_file.write('<div class=\"aspect aspect--2x3\">')\n",
    "            html_file.write('<div class=\"aspect__inner\">')\n",
    "            if cleanTitle3(row['filename']) + '.jpg' in os.listdir(\"./Site/pages/posters/\"):\n",
    "                html_file.write('<a href=\"./pages/'+ title + '.html\"><img src=\"pages/posters/' + cleanTitle3(row['filename']) + '.jpg\" class=\"face pic\"/></a>')\n",
    "            else:\n",
    "                html_file.write('<a href=\"./pages/'+ title + '.html\"><img src=\"pages/images/NA.jpg\" class=\"face pic\"/></a>')\n",
    "            html_file.write('</div>')\n",
    "            html_file.write('</div>')\n",
    "            html_file.write('<div class=\"titlediv\" style=\"height:25px;top: 87%;\">')\n",
    "            html_file.write('<figcaption name=\"title\" class=\"titletext\" style=\"font-size:0.9em\"><a href=\"./pages/' + title + '.html\" target=\"_blank\">' + title + '</a></figcaption>')\n",
    "            html_file.write('</div>')\n",
    "            html_file.write('</div>')\n",
    "            html_file.write('</figure>')\n",
    "        \n",
    "        html_file.write(footer)\n",
    "        html_file.close()\n",
    "        logger.info(\"Homepage Complete\")\n",
    "        \n",
    "        #Create SubPages        \n",
    "        for index, row in movieDF.iterrows():\n",
    "            title = cleanTitle(row['filename'])\n",
    "            \n",
    "            movie_page = \"./Site/pages/\" + title + \".html\"     \n",
    "            html_file = open(movie_page, \"w\")\n",
    "            html_file.write(header_sub)\n",
    "            \n",
    "            if cleanTitle3(row['filename']) + '.jpg' in os.listdir(\"./Site/pages/posters/\"):\n",
    "                html_file.write('<img src=\"posters/' + cleanTitle3(row['filename']) + '.jpg\" class=\"img-bk\"/>')\n",
    "            html_file.write('<a href=\"../movies.html\"><img src=\"images/backarrow.png\" class=\"back-button\"/></a>')\n",
    "                \n",
    "            html_file.write('<div id=\"content\">')\n",
    "            html_file.write('<div class=\"col-md-4\">')\n",
    "            if cleanTitle3(row['filename']) + '.jpg' in os.listdir(\"./Site/pages/posters/\"):\n",
    "                html_file.write('<img src=\"posters/' + cleanTitle3(row['filename']) + '.jpg\" class=\"coverart\"/>')\n",
    "            else:\n",
    "                html_file.write('<img src=\"images/NA.jpg\" class=\"coverart\" />')\n",
    "                \n",
    "            html_file.write('</div>')\n",
    "            html_file.write('<div class =\"col-md-8\" style=\"padding-left:30px; padding-right:30px\"><br>')\n",
    "            html_file.write('<p class=\"titleshadow\" id=\"movie\">' + str(row['title']) + '</p><p class=\"movieyear\" id=\"year\">' + str(row['year']) + '</p>') \n",
    "            html_file.write('<hr class=\"title-border\">') \n",
    "            html_file.write('<p class=\"runtime\" id=\"runtime\">' + str(row['duration']) + '</p><p class=\"genres\" id=\"genre\">' + str(row['genre']) +'</p><br><br>')\n",
    "            \n",
    "            html_file.write('<div class =\"col-md-9\"><br>')\n",
    "            html_file.write('<p class=\"elements\">Plot: </p> <p class=\"desctext\">' + str(row['plot']) + '</p><br><br>')\n",
    "            html_file.write('<p class=\"elements\">Actors: </p> <p class=\"desctext\">' + str(row['actors']) + '</p><br><br>')\n",
    "            html_file.write('<p class=\"elements\">Director: </p> <p class=\"desctext\">' + str(row['director']) + '</p><br><br>')\n",
    "            html_file.write('<p class=\"elements\">Release Date: </p> <p class=\"desctext\">' + str(row['release_date']) + '</p>')\n",
    "            \n",
    "            html_file.write('<hr>')\n",
    "            html_file.write('<a href=\"file://' + dirClean(source_dir) + row['filename'] + '\" download><img src=\"images/download.png\" class=\"icons\"></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"file://' + dirClean(source_dir) + row['filename'] + '\"><img src=\"images/play.png\" class=\"icons\"></a>')\n",
    "              \n",
    "            html_file.write('</div>')\n",
    "            html_file.write('<div class =\"col-md-3\"><br>')\n",
    "            \n",
    "            #Ratings Pane\n",
    "            ##MPAA Rating\n",
    "            html_file.write('<center><span class=\"mpaa\">' + str(row['mpaa_rating']) + '</span></center><hr>')\n",
    "            ##IMDB Rating\n",
    "            html_file.write('<center><p class=\"rating\" style=\"padding-bottom: 2px\"><b>IMDB</b><br>' + str(row['rating_imdb']) + '/10</p></center><hr>')\n",
    "            ##Metacritic Rating\n",
    "            html_file.write('<center><p class=\"rating\" style=\"padding-bottom: 2px\"><b>Metacritic</b></p>')           \n",
    "            if row['rating_metacritic'] <= 20: \n",
    "                html_file.write('<span class=\"metalow\">' + str(int(row['rating_metacritic']))+'</span></center>')\n",
    "            elif 20 < row['rating_metacritic'] <= 40: \n",
    "                html_file.write('<span class=\"metamedlow\">' + str(int(row['rating_metacritic']))+'</span></center>')   \n",
    "            elif 40 < row['rating_metacritic'] <= 60: \n",
    "                html_file.write('<span class=\"metamedium\">' + str(int(row['rating_metacritic']))+'</span></center>')    \n",
    "            elif 60 < row['rating_metacritic'] <= 80: \n",
    "                html_file.write('<span class=\"metamedhigh\">' + str(int(row['rating_metacritic']))+'</span></center>')    \n",
    "            elif row['rating_metacritic'] > 80: \n",
    "                html_file.write('<span class=\"metahigh\">' + str(int(row['rating_metacritic']))+'</span></center>') \n",
    "            else:\n",
    "                html_file.write('<span class=\"metaNA\">NA</span></center>')\n",
    "            html_file.write('<hr>')\n",
    "            \n",
    "            ##Rotten Tomatoes\n",
    "            html_file.write('<center><p class=\"rating\" style=\"padding-bottom: 2px\"><b>Rotten Tomatoes</b><br>' + str(row['rating_rotten']) + \" \")\n",
    "            if row['rating_rotten'] < 60: \n",
    "                html_file.write('<img src=\"images/rottenicon.png\" style=\"width:30px; display:inline\"></p></center>') \n",
    "            elif row['rating_rotten'] >= 60: \n",
    "                html_file.write('<img src=\"images/freshicon.png\" style=\"width:30px; display:inline\"></p></center>')\n",
    "            else:\n",
    "                html_file.write('</p></center>')\n",
    "\n",
    "            html_file.write('</div></div></div>')\n",
    "\n",
    "            html_file.write(footer_sub)\n",
    "            html_file.close()\n",
    "            logger.info(\"Success - \" + title + '.html')\n",
    "        \n",
    "        # Opening the browser and presenting the summary html page\n",
    "        webbrowser.open('file://' + os.path.realpath(output_file))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        traceback.print_tb(e)\n",
    "        print(\"***** Error. Maybe try to run the script again but bit later? *****\")\n",
    "        logger.critical('Critical error -- Abort Script')\n",
    "        sys.exit(0)\n",
    "        \n",
    "    #write to Logger\n",
    "    logger.info('htmlout() function complete')\n",
    "    print(\"htmlout() END\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
